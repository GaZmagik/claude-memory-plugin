---
type: breadcrumb
title: "Think: Accord Plugin - Autonomous agent orchestration platform with persistent memory and dashboard"
topic: Accord Plugin - Autonomous agent orchestration platform with persistent memory and dashboard
status: concluded
created: "2026-01-30T17:15:33.481Z"
updated: "2026-01-30T18:01:35.360Z"
tags:
  - think
  - concluded
scope: project
conclusion: |-
  Multi-agent architectural deliberation on Accord plugin has converged on several key insights:

  **Architecture Consensus:**
  - Daemon + plugin hybrid (NOT pure plugin) - daemon handles scheduling/execution, plugin provides control plane
  - Memory plugin as canonical state store for agent deliberations/decisions (NOT shadow .state.json files)
  - Agent working memory (execution history, budgets, schedules) in separate state files
  - Message queue-based IPC between daemon and Claude Code sessions (survives crashes)
  - Decision checkpoint model for transparency and observability

  **Critical Implementation Requirements:**
  - Graceful shutdown with append-only transaction logs (survive crashes)
  - Process-level token budget monitoring across all agents
  - Agent config versioning (prevent mid-execution reconfiguration)
  - Centralized agent registry (single source of truth, avoid orphaned resources)
  - Structured termination events (success, budget-exceeded, timeout, crash)

  **Developer Experience Priorities:**
  - Instrumented documentation (executable examples, not hypothetical)
  - Symptom-first troubleshooting guides
  - Request-response traces for API documentation
  - Document failure modes explicitly and early (build trust through transparency)
  - Observe-then-configure onboarding flow

  **Key Architectural Risks Identified:**
  - Configuration fragmentation (4 places to configure agents)
  - Multi-file transactions without transactional semantics (orphaned state)
  - Temporal coupling (agent running with old config during reconfiguration)
  - State file locking (concurrent writes during parallel meetings)

  **Next Steps:**
  1. Decide: Build Accord as separate project or defer to focus on memory plugin v1.2.0+
  2. If proceeding: Start with manual /meeting skill (MVP) before scheduled meetings
  3. Prototype centralized agent registry with JSON-schema validation
  4. Design state file format (append-only, version-stamped, crash-safe)

  This deliberation has validated the feasibility of Accord while surfacing critical architectural challenges that must be addressed before implementation.
promotedTo: decision-accord-plugin-autonomous-agent-orchestration-platf
---

# Accord Plugin - Autonomous agent orchestration platform with persistent memory and dashboard

_Thinking document created 2026-01-30T17:15:33.481Z_

## Thoughts

### 2026-01-30T17:15:50.220Z - Thought
Accord plugin scope: (1) Schedule AND execute meetings, (2) Persistent working agents with local memory, (3) Agent config via .claude/agents/*.local.md (YAML frontmatter: name, subagent_type, output_style, model, tools), (4) Frontend dashboard showing meetings/agents/status/projects, (5) Integration with memory plugin for per-agent memory isolation. Core innovation: agents as persistent entities with their own context, not ephemeral Task tool spawns.

### 2026-01-30T17:16:05.616Z - Thought
Agent persistence architecture: Each agent gets isolated memory scope via memory plugin integration. Pattern: .claude/agents/typescript-mentor.local.md → agent runs with memory scope='agent:typescript-mentor'. Memory plugin already supports project/global/temporary scopes; need to add 'agent' scope. Agent state includes: (1) Memory graph (decisions/learnings specific to agent's work), (2) Active deliberations (agent-specific think sessions), (3) Execution history (what tasks completed, when). Challenge: prevent memory pollution between agents working on same codebase.

### 2026-01-30T17:16:20.293Z - Thought
Frontend dashboard architecture: Three options: (1) Web-based (Electron/Tauri app serving React/Svelte UI), (2) Terminal UI (Ratatui/Ink for in-terminal dashboard), (3) Hybrid (TUI primary, web optional). Dashboard must show: real-time agent status, scheduled meetings, project progress, memory graph health, API usage metrics. Critical: dashboard must NOT require Claude Code session to be active - needs persistent backend service. This implies Accord needs daemon mode, which Claude Code lacks. Architecture gap: how does dashboard communicate with scheduled agents if both run outside Claude Code sessions?

### 2026-01-30T17:16:34.996Z - Thought
Security and resource management: CRITICAL concerns: (1) Runaway agents - autonomous agent enters infinite loop, burns £100+ in API costs overnight, (2) Code execution permissions - working agents need write access to codebase, potential for malicious edits, (3) API key security - agents need persistent access to Claude/Codex/Gemini APIs, key storage/rotation needed, (4) Resource quotas - per-agent token budgets, rate limiting, circuit breakers. Mitigation strategies: agent sandboxing, dry-run mode, human-in-loop approval gates for destructive operations, observable agent reasoning via memory think integration.

### 2026-01-30T17:16:50.017Z - Thought
Fundamental architecture question: Can Accord be a Claude Code plugin, or must it be a separate service? Claude Code plugins are reactive (hooks triggered by user events), not proactive (no daemon mode). Accord needs: (1) Persistent background service for scheduling, (2) Agent orchestrator running independently of user sessions, (3) Dashboard server. This suggests Accord CANNOT be a pure plugin. Options: (1) Standalone Bun/Node service + Claude Code plugin for integration, (2) Claude Code plugin that spawns persistent daemon on first use, (3) Separate Electron/Tauri app that embeds Claude Code SDK. Hybrid approach most viable: Accord daemon + thin Claude Code plugin for memory integration.

### 2026-01-30T17:19:34.761Z - Thought (model:haiku style:Pragmatist agent:typescript-expert [a921c2af-8194-4b09-8a91-db0bcb769448])
Memory model architecture reveals a critical insight: agent persistence shouldn't rely on memory plugin scope isolation alone. The plugin's memory system is designed for *human-readable knowledge capture* (decisions, learnings, gotchas), not *agent state management*. Mixing these concerns creates operational friction. Better architecture: agents maintain their own state files (.claude/agents/[name].state.json) containing execution history, active tasks, token usage, error logs. Memory plugin integration becomes *selective* - agent chooses what to promote to persistent knowledge (a successful pattern discovered, a gotcha to avoid). This separation means agents can operate offline from the memory plugin entirely, making them truly persistent without depending on plugin availability.

The daemon question resolves to a practical answer: Accord daemon is Node.js + Bun, Claude Code plugin provides *synchronous* integration points only (trigger an agent run now, check status now), not async scheduling. Real scheduling lives in daemon via node-cron. Dashboard is dashpoard server running alongside daemon, stateless, queries daemon state files. This keeps the plugin lightweight and reactive - it never tries to be a scheduler. Claude Code's job is to spawn agents via the Task tool and pass their metadata; Accord daemon manages lifecycle. The plugin becomes the *control plane* (user configures agents, reviews dashboards), daemon is the *execution plane*.

Cost control becomes tractable through a simple mechanism: each agent has a .claude/agents/[name].budget.json file containing token allowance, spend-to-date, reset schedule. Daemon checks this before spawning each Task. Runaway loop protection: agent execution has a hard timeout (configurable, default 30 mins), after which Task is killed regardless of progress. No infinite loops. Memory think sessions (agent deliberation) count towards budget but are capped at token-efficient depths.

TypeScript architecture benefit: agents defined as statically typed entities (interface Agent with name, subagent_type, tools, model, budget). Configuration via YAML frontmatter in .local.md files gets parsed into Agent objects at daemon startup. Type safety prevents config mistakes (invalid subagent_type, unsupported model combo). Dashboard UI built as SvelteKit static site served by daemon server, queries `/api/agents`, `/api/status`, `/api/memory-graph`. No Electron/Tauri complexity.

The real innovation isn't persistent agents (that's a solved problem with state files). It's *deliberative agents* - agents that think through complex decisions using memory think, capture reasoning as learnings, build context across multiple runs. This requires tight memory plugin integration for the *thinking layer* specifically. Execution state is boring (JSON files). Thought artifacts are valuable (persist across runs, agents reference each other's conclusions).

Human-in-the-loop doesn't need gates on every operation. It needs *observability*. Agent reasoning visible via dashboard (show the memory think transcript), last-run output visible, commit diffs reviewable before they hit main branch. Agents submit PRs or branches, not direct commits. This trades autonomy for safety without killing the concept.

### 2026-01-30T17:20:29.857Z - Thought (model:haiku agent:ui-ux-design-expert [35cd48a6-d5e5-49ff-aa5a-c1f90ebd3130])
Working agents operating in autonomous mode creates a novel transparency problem: developers can't directly observe agent reasoning in real-time (no REPL, no step-through debugging). The dashboard becomes the primary mechanism for trust-building, but visual status indicators alone are insufficient—they're too abstract. Consider: a developer sees "Agent: typescript-mentor [IN_PROGRESS] 45% complete" but has no idea *why* the agent chose to refactor three unrelated files, or whether those changes align with project patterns.

Solution: surface agent *decision trails*. Each agent decision (file to modify, test to write, refactor to perform) gets logged with its reasoning—pulled directly from agent memory think sessions. Dashboard shows a collapsible decision tree per agent: "Why did this agent modify X? → Agent reasoning: 'Found circular dependency in module Y, refactoring improves type safety.' → Memory check: Pattern 'circular-dep-refactor' found in decisions." This gives developers *auditable reasoning* without reading sprawling agent logs.

Critical UX pattern: agent decisions should be *previewable before execution*, not just reviewable after. Generate a "execution plan" view showing all files the agent intends to touch, changes to make, tests to write—like a detailed git diff preview before commit. Developers can "approve and continue" or "pause and investigate" before autonomous work happens. This shifts trust from "I hope the agent doesn't break things" to "I understand what the agent will do, and I've approved it."

However, this creates operational tension: if every agent decision requires developer approval, you've lost autonomy. The approval gate should be *intelligent and graduated*: (1) Low-risk changes (adding tests, documentation) → automatic, (2) Medium-risk (refactoring within module boundaries) → async approval (developer reviews in background, agent proceeds if no objections within threshold), (3) High-risk (breaking API changes, deleting code) → synchronous approval required. Memory plugin plays a role here: agent learns which approval patterns work for a given codebase, adapts to team's risk tolerance over time.

One more consideration: agent *failure modes* are asymmetric. A human developer who writes buggy code self-corrects (runs tests, sees failures, fixes). An autonomous agent in degraded state (corrupted state file, API rate-limited, memory plugin offline) might silently fail or retry infinitely. Dashboard needs early warning signals: agent hasn't reported status in N seconds, memory access is failing, API errors are accumulating. Add a "heartbeat" mechanism where agents periodically check-in with daemon, and dashboard surfaces anomalies visually.

### 2026-01-30T17:21:13.920Z - Thought (model:haiku agent:security-code-expert [a3ef5f87-a3b1-43be-97f3-d39b1b891d74])
The security threat model reveals a fundamental architectural tension: the more autonomous and persistent these agents become, the more they resemble privileged services on the developer's machine. But the threat severity diverges sharply from the implementation difficulty.

The runaway agent problem (cost explosion) is actually the *easiest* to solve and shouldn't drive architecture. A simple token budget enforcer with per-agent spend caps is straightforward—agents get a quota (£10/day, for example), and exceeding it triggers automatic shutdown. This is pure accounting. The UI problem is trivial: show remaining budget in the dashboard, let developers adjust caps. Done.

The malicious code edit problem is harder but often overestimated. The real constraint isn't preventing writes—it's *observability*. If an agent modifies code, a developer should see the diff *before* it's committed. This means agents shouldn't push to git directly; instead they stage changes and send notifications. The git history becomes an audit trail. An agent that consistently makes questionable edits becomes obviously untrustworthy through its track record, not through access control.

API key security is genuinely thorny but solvable at the daemon layer, not the agent layer. Keys shouldn't be stored in `.claude/agents/` at all—they should live in a secrets manager (OS keychain, 1Password, HashiCorp Vault). The daemon reads keys on startup, passes them to agents via environment variables scoped to that process only. If an agent is compromised, the attacker gets a single set of ephemeral credentials that expire when the agent dies, not permanent key material. This is standard practice for long-running services.

Memory pollution as a security vector is being misframed. The real risk isn't that an agent poisons its own memory graph—that's captured in audit trails anyway. The risk is that an agent *learns* to exploit a gap in your project's patterns, discovers that "if I reformat this config file, the tests skip the security checks," and now future agents have access to that knowledge. The mitigation is brutal but necessary: agent memory should be *ephemeral by default*. An agent only gets access to project-level and global memory, not persistent agent-specific memory, unless *explicitly promoted by a human reviewer*. No automatic "learning" from one agent run to the next.

Daemon compromise is the most serious threat because it's the final layer. But it's also where the risk model inverts: if someone has compromised the daemon running on your machine, your security posture is already lost. The daemon is running as your user, with your credentials, in your codebase. At that point, you've got bigger problems. The mitigation is operational, not architectural: sandboxed environments (containers, VMs) for untrusted agents, audit logging at the OS level, and strict least-privilege for what agents can access.

The insight: security theater doesn't help. Don't build elaborate permission systems that create false confidence. Instead, focus on *transparency + auditability*. Every agent action gets logged, diffs are visible before commit, budgets are enforced, and compromised agents can be revoked instantly. The security model becomes "assume agents will be exploited, but make sure we catch it fast," not "assume we can prevent exploitation through clever design."

### 2026-01-30T17:22:00.067Z - Thought (model:haiku style:Architect agent:rust-expert [7db2103c-b856-4cb6-bc2c-8a254aaaa78e])
The split between daemon and plugin creates an execution boundary problem that cascades through the entire architecture. The daemon owns scheduling and agent lifecycle, but agent execution—code analysis, file writes, API calls—happens within Claude Code's tool ecosystem. This creates two failure modes:

First, information asymmetry: the daemon schedules "typescript-mentor reviews payment module," but execution happens in a Claude Code session where that agent has no persistent context of previous reviews, project patterns they've already documented, or decisions they've made. Each session, the agent starts cognitively fresh. This defeats the "persistent agent" thesis entirely. You need agents to carry forward learned patterns across sessions.

Second, the state file approach (mentioned by typescript-expert) solves one problem but creates another: agents write to `.claude/agents/[name].state.json`, but that state is just JSON. It's not queryable, not integrated with the memory plugin's graph capabilities, and it's a parallel state management system competing with the memory plugin that already exists. This is technical debt. If memory plugin already supports scope isolation, that's the canonical state store—don't create a shadow state system.

Better synthesis: agents carry memory *actively* through a scoped memory context during execution. When daemon spawns an agent in a Claude Code session, it passes `--memory-scope=agent:typescript-mentor` to the SDK invocation. The agent's entire working context—decisions, learnings, previous patterns—flows through the memory plugin during that execution window. No separate state files. The agent's reasoning becomes both executable *and* observable through memory think sessions, which the UI/UX layer can surface in the dashboard.

This solves the transparency problem too: the dashboard shows not just "IN_PROGRESS 45%," but can query the agent's active memory think for why it's making specific choices. Developers see the reasoning in real-time (or near-real-time via polling), building trust through observability rather than abstract status bars.

Security simplifies around this too: agent API keys are daemon-managed secrets, never written to disk in agent sessions. The daemon injects credentials at invocation time, agents use them within the scoped execution window, credentials evaporate when the session ends. Memory plugin becomes the audit trail—all agent decisions are recorded with timestamps and can be queried for forensic review if something goes wrong.

The minimal viable architecture: (1) Accord daemon written in Bun/Node, owns scheduling and credential management, (2) Accord Claude Code plugin, minimal surface area—just memory scope integration and dashboard communication, (3) Agent specs stored as `.claude/agents/[name].local.md`, (4) Memory plugin as the canonical state store, no shadow files, (5) Dashboard pulls data from daemon API. The daemon does heavy lifting, the plugin is the integration point, memory plugin is the brains.

### 2026-01-30T17:22:48.048Z - Thought (model:haiku agent:performance-optimisation-expert [ed81bef0-34ba-475e-9ff7-455493650ef7])
The resource management challenge exposes a subtle architectural asymmetry: you're treating agent memory as *persistent state* when it should be *ephemeral working space with selective capture*. Current thinking conflates two separate problems.

**Memory bloat scenario**: If an agent runs daily tasks and logs every decision to its memory graph, within 6 months you have thousands of nodes. The memory plugin's graph algorithms degrade gracefully (it's designed for this), but the real problem is semantic pollution—the graph becomes a journal of mistakes rather than a knowledge base. Solution isn't better pruning; it's *agent memory architecture that distinguishes between working memory and persistent memory*. Working memory = agent's current task context, lives in `.state.json`, gets wiped after each execution window. Persistent memory = hand-curated patterns, gotchas, successful strategies, promoted *selectively* by the agent itself using decision points. This mirrors human working memory, not permanent storage.

**Parallel execution bottleneck**: Five agents running simultaneously isn't inherently expensive—concurrent API calls are fine. The actual bottleneck is *token budget visibility*. Without real-time tracking, agents don't know when they're approaching quota and make poor decisions (continue expensive analysis vs. bail and summarise). The fix: each agent gets a token budget object updated in-memory as calls execute, and the agent's system prompt includes "you have X tokens remaining in this session—optimise for completion probability". Dashboard doesn't need to poll API every second; it pulls agent state snapshots every 30-60 seconds. Agents export minimal state: `{task_id, phase, tokens_used, eta_completion, last_checkpoint}`. This is 100 bytes per agent, 5 agents every minute = negligible load.

**Scheduled meetings resource allocation**: The real problem here is *greedy reservation*. If you schedule five agents to run simultaneously, you're not multiplying cost—you're serialising it badly by making them wait. Better model: "schedule this team for 2 hours starting at 9am, agents self-organise within that window." One agent might finish in 15 minutes, freeing tokens for others. This requires task dependency tracking and a simple scheduler inside the daemon (not complex, just topological sort of agent tasks). The dashboard shows the *meeting window* with actual agent runtime, not five independent timelines.

**The fundamental insight**: You're optimising the wrong layer. Memory bloat, polling overhead, and token waste aren't daemon architecture problems—they're *poor information scoping* problems. Solve for: (1) agents only persist knowledge they intentionally decide to keep, (2) dashboard reads snapshot state, not real-time streams, (3) token budgets are agent-visible constraints, not post-hoc monitoring. With these constraints explicit, the architecture self-optimises because agents become incentivised to work efficiently. A runaway agent hits its token budget and stops itself—no circuit breaker needed. An agent working on a low-value task cancels when it realises budget is tight. This is less "resource management" and more "resource visibility transparency".

### 2026-01-30T17:23:32.920Z - Thought (model:haiku agent:frontend-tester-expert [13b1db05-291c-4dbd-881e-52606ccdda40])
The dashboard-agent feedback loop creates a critical observability gap that existing architectures overlook. Real-time status indicators (IN_PROGRESS, 45% complete) fail because they're decoupled from *why* the agent made those choices. The transparency problem isn't solved by showing memory think transcripts—that just moves the complexity sideways. Instead, consider a "decision checkpoint" model where agents emit structured decision events at meaningful boundaries: before entering refactoring, after evaluating alternatives, when encountering ambiguity. These checkpoints aren't logs—they're query-able decision breadcrumbs that the dashboard can reconstruct into a causal narrative. A developer doesn't see "Agent refactored three files"; they see "Agent evaluated [option A: minimal changes], [option B: comprehensive refactor], chose B because [reasoning from decision checkpoint]." The dashboard filters/summarizes these checkpoints based on project trust level—low-trust projects show everything, high-trust projects collapse non-critical decisions. This inverts the testing problem: instead of testing that the dashboard *displays* agent state, you test that decision checkpoints *encode enough context* for a human to reconstruct intent. Test vectors become: (1) checkpoint fidelity—does the checkpoint capture the actual decision branches the agent evaluated? (2) reconstruction accuracy—can a developer read checkpoints and understand why the agent acted? (3) filtering efficiency—do the dashboard filters reduce checkpoint volume without losing critical information? The architectural win: decision checkpoints work offline, survive agent failures (stored in agent state files), and provide the transparency needed to trust autonomous systems. They're also composable—an agent can query *other agents'* checkpoints to avoid duplicating work or contradicting prior decisions.

### 2026-01-30T17:57:38.906Z - Thought (model:haiku agent:nodejs-expert [ed536cca-a0ca-4d41-b9b0-f16cfa7ceab4])
The daemon-plugin split reveals a critical operational complexity in Node.js/Bun that existing thoughts haven't addressed: process lifecycle management becomes non-trivial when agents must survive across Claude Code session boundaries.

Current thinking assumes a persistent daemon spawned on first use, but production Node.js services require graceful shutdown, signal handling, and state recovery. Consider the failure cascade: developer closes Claude Code while an agent is mid-execution. The daemon process either (1) forcefully terminates, losing in-flight work and corrupting state files, or (2) continues running orphaned, consuming resources and API quota while becoming invisible to the user.

Better architecture: adopt Node.js graceful shutdown patterns. The daemon registers handlers for SIGTERM/SIGINT, implements a timeout-bounded shutdown sequence (finish current agent task, flush state files, close database connections), and persists agent execution context to disk. State file format should be append-only transaction log, not overwritten snapshots—this survives crashes and enables replaying partial work on restart.

The IPC mechanism matters here. Using HTTP for daemon-to-plugin communication (localhost socket) is simpler than unix domain sockets but introduces lifecycle coupling: if the daemon crashes, the Claude Code session hangs on IPC calls. Better pattern: use message queues (fs-backed queue, Redis if available) where Claude Code sessions push agent requests, daemon consumes asynchronously. On daemon restart, unconsumed requests replay automatically. Decouples lifecycle failure modes.

For scheduling, `node-cron` is viable but introduces yet another long-running Node.js process. Alternative: store scheduled meetings in state files (JSON with cron expression + last execution time), let the daemon check on a fixed interval (every 30 seconds). Simpler, fewer dependencies, survives process restarts (just resume from last-execution-time). The cost is 30-second scheduling granularity instead of per-minute, which is acceptable for agent meetings.

The deeper insight: persistent agent architecture in Node.js requires treating the daemon like a production microservice, not a background helper. This means structured logging (JSON lines for easy parsing by dashboard), health check endpoints, metrics export (tokens used, agents active, error rates), and—critically—runaway prevention via built-in resource monitors. Add a process-level token budget: daemon tracks cumulative tokens across all agents, pauses agents if budget approaches limit, surfaces this to dashboard for developer intervention.

One architectural risk: state file locking. Multiple agents writing to `.claude/agents/[name].state.json` concurrently (unlikely but possible during parallel scheduled meetings) causes corruption. Use file-based locking (check-then-write with retry logic) or move to a lightweight embedded database like better-sqlite3. For Bun compatibility, better-sqlite3 works fine; for pure Node.js, it's the only option.

### 2026-01-30T17:59:15.291Z - Thought (model:haiku agent:code-quality-expert [163fec49-ebf4-4aa6-b48a-c72eb3316c30])
I appreciate the meticulous guidance, but I notice the user input is empty and this appears to be the skill's internal documentation rather than an invocation request.

Since you've asked me to add a thoughtful analysis to the Accord plugin deliberation, let me proceed directly with that contribution:

---

The daemon-plugin hybrid architecture creates a critical separation-of-concerns problem that existing thoughts underestimate: the maintainability burden compounds non-linearly as configuration complexity grows.

Consider the current thinking: agents are configured via `.claude/agents/*.local.md` with YAML frontmatter (name, subagent_type, output_style, model, tools). But this is only the *declared* configuration. The *operational* configuration—token budgets, scheduling expressions, fallback models, resource quotas, retry policies, error callbacks—must live somewhere. If it stays in agent config files, you've buried operational concerns in what should be a thin metadata layer. If it lives in a separate `agent-budgets.json` or scheduling daemon config, you've split agent identity across two files, making it fragile to refactor (rename an agent, forget to update the budget file).

This directly impacts code maintainability: every agent CRUD operation (create, rename, delete, modify permissions) becomes a multi-file transaction. Without transactional semantics, you can orphan resources—a deleted agent config leaves behind budget entries, scheduled tasks, memory state files. This isn't just untidy; it's a debugging nightmare. A developer investigates a mysterious failed scheduled task, discovers it references a deleted agent, has no clear remediation path.

**Testing strategy implication**: You cannot unit-test agent lifecycle in isolation. Tests must verify cross-file consistency. This demands a fixture setup that's brittle and expensive—every test needs a complete agent skeleton (config + budget + schedule + memory directory). Consider instead: centralised agent registry stored as a single JSON schema that can be snapshot-tested, validated via JSON-schema, and transactionally updated. The `.local.md` files become *projections* of this canonical source, generated by a build step. This inverts the dependency: tests operate on the registry, the CLI generates config artifacts. Maintenance cost drops dramatically—refactor the registry schema once, tests adapt automatically, no orphaned state.

**Developer experience for debugging failed runs**: The decision checkpoint model from the frontend-tester thought is sound, but it assumes the agent completed enough execution to emit checkpoints. What about crashes? A working agent encounters an API error at token budget exhaustion, fails silently because no error callback is configured. The developer finds a half-written file in git, a memory think session with three unfinished thoughts, no indication of *why* the agent stopped. The daemon logs would show "Agent 'typescript-mentor' exited with code 127" but not the context. Better: agents emit structured termination events (success, budget-exceeded, api-error, timeout, crash) with full context captured in agent state files. The dashboard queries these state files to surface "why did it stop?" instantly. This requires: (1) agent state schema versioning (state files evolve as agent capabilities grow), (2) termination handlers that fire even on crash (Bun's `beforeExit` hook helps here), (3) state file rotation (otherwise a long-running daemon accumulates gigabytes of history).

**Configuration complexity**: The hybrid architecture distributes configuration authority across four places: (1) Claude Code plugin settings (which agents are enabled), (2) agent `.local.md` files (agent metadata), (3) daemon config (scheduling, resource limits), (4) memory plugin scopes (agent isolation rules). This is architectural fragmentation. A developer enabling a new agent must touch all four places. A single source of truth—an `accord-config.json` that subsumes all four layers—would reduce friction. But this creates a new problem: Claude Code plugins have no standard way to edit structured JSON config from the UI (they can only read/write markdown via plugin-settings skill). So you'd need a custom command `/accord-config edit` that opens an interactive configurator, which is non-trivial to build and maintain.

**Technical debt early warning**: The decision-checkpoint + agent-state-files architecture scales better than distributed configuration, but it introduces a temporal coupling problem. An agent running in the daemon might emit checkpoints while the developer is modifying the agent config in Claude Code. The daemon loads new config, but the in-flight agent has the old config cached. This causes *silent* inconsistency—the checkpoint references a tool that no longer exists in the new config. Mitigation: agents must refresh config on each task boundary, not at startup. This adds latency and complexity. Better mitigation: make agent config immutable after scheduling (version the config, agents reference a config version ID, not the live config file). This prevents surprise mid-execution reconfiguration but requires versioning infrastructure.

**Documentation requirements**: The configuration is now non-trivial. A developer needs to understand: agent lifecycle (create, enable, schedule, run, archive), memory isolation scopes, resource budgets, error handling, decision checkpoints. This demands end-to-end documentation that covers not just the *what* (here's the YAML schema) but the *why* (why would you set token_budget to 50k instead of 100k?) and the *gotchas* (what happens if two agents run simultaneously on overlapping files?). Documentation that's incomplete here will result in hours of wasted debugging time per user. Mitigation: embed decision rationale in the agent config schema as JSON-schema `description` fields. Then generate documentation from the schema automatically. A developer reading the config file gets inline guidance. This prevents documentation drift—the schema is the source of truth.

### 2026-01-30T18:00:47.491Z - Thought (model:haiku agent:documentation-accuracy-expert [2b1e75ac-8ede-42a0-99dc-81f74e802940])
The documentation problem for Accord is fundamentally a *trust deficit* problem masquerading as a clarity problem. Users won't adopt autonomous agents because they can't predict or understand agent behaviour—and traditional documentation (API reference, setup guides, architecture diagrams) doesn't solve that because it treats agent behaviour as *deterministic and debuggable*, when it's actually *stochastic and emergent*.

Most documentation assumes the user's mental model progresses linearly: read setup → read API → understand architecture → use confidently. But autonomous agents break this assumption. A developer might follow the setup guide perfectly, spawn an agent, watch it make three reasonable decisions, then make one baffling choice that contradicts project conventions. The question isn't "how do I call this API?"—it's "why did the agent do that, and how do I prevent it next time?" Standard documentation has no answer because it predates the question.

The solution isn't *more* documentation—it's *instrumented documentation*. Every key Accord concept (agent lifecycle, memory scoping, meeting scheduling, decision checkpoints) should come with embedded examples that the user can actually run and observe in their own projects. Not hypothetical examples—executable ones.

Concrete approach: build a `accord init --example typescript-mentor` flow that scaffolds a minimal working agent with a corresponding tutorial project that exercises that agent repeatedly. The tutorial isn't a markdown file; it's a live project with comments at each phase: "Agent should now decide to add type annotations here—watch the decision checkpoint to see why it chose that approach." When the agent behaves unexpectedly, the tutorial becomes a regression test. When it behaves correctly, it becomes a confidence baseline.

For onboarding specifically, the mental model progression should be inverted: start with *observing* agent behaviour (run a simple agent, watch memory, inspect decision checkpoints) before explaining *how to configure* agents. Users need visceral understanding that agents have consistent reasoning patterns before they're ready to read configuration documentation.

The troubleshooting guides should be structured by *symptom*, not by component. Don't have a section titled "Agent Memory Configuration"—instead have "Agent keeps making the same mistake repeatedly" → check decision checkpoints to see if agent evaluated alternatives, check memory scope isolation to ensure previous corrections persisted, check if agent model has sufficient context window. Symptoms-first documentation naturally guides users toward the root cause.

API documentation for daemon endpoints should include *request-response traces* from real executed scenarios, not just parameter lists. Show what happens when you schedule an agent meeting while an agent is already executing—include the actual JSON payloads, the timing, the failure mode if applicable. Users learn by pattern-matching their situation against observed traces.

One final critical point: document the *failure modes explicitly and early*. Don't bury "agents can enter infinite loops" in a security appendix—feature it prominently in the quickstart with a worked example: "Here's what happens if you give an agent insufficient token budget, how the daemon detects it, and how to recover." Users trust systems more when they understand exactly how they fail. This inverts the confidence problem—instead of users being nervous about autonomy they don't understand, they're confident because they know the guardrails.

### 2026-01-30T18:01:35.359Z - Conclusion
Multi-agent architectural deliberation on Accord plugin has converged on several key insights:

**Architecture Consensus:**
- Daemon + plugin hybrid (NOT pure plugin) - daemon handles scheduling/execution, plugin provides control plane
- Memory plugin as canonical state store for agent deliberations/decisions (NOT shadow .state.json files)
- Agent working memory (execution history, budgets, schedules) in separate state files
- Message queue-based IPC between daemon and Claude Code sessions (survives crashes)
- Decision checkpoint model for transparency and observability

**Critical Implementation Requirements:**
- Graceful shutdown with append-only transaction logs (survive crashes)
- Process-level token budget monitoring across all agents
- Agent config versioning (prevent mid-execution reconfiguration)
- Centralized agent registry (single source of truth, avoid orphaned resources)
- Structured termination events (success, budget-exceeded, timeout, crash)

**Developer Experience Priorities:**
- Instrumented documentation (executable examples, not hypothetical)
- Symptom-first troubleshooting guides
- Request-response traces for API documentation
- Document failure modes explicitly and early (build trust through transparency)
- Observe-then-configure onboarding flow

**Key Architectural Risks Identified:**
- Configuration fragmentation (4 places to configure agents)
- Multi-file transactions without transactional semantics (orphaned state)
- Temporal coupling (agent running with old config during reconfiguration)
- State file locking (concurrent writes during parallel meetings)

**Next Steps:**
1. Decide: Build Accord as separate project or defer to focus on memory plugin v1.2.0+
2. If proceeding: Start with manual /meeting skill (MVP) before scheduled meetings
3. Prototype centralized agent registry with JSON-schema validation
4. Design state file format (append-only, version-stamped, crash-safe)

This deliberation has validated the feasibility of Accord while surfacing critical architectural challenges that must be addressed before implementation.
